{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2, requests, pandas as pd\n",
    "from config import host, user, password, db_name, api_key\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_connection ():\n",
    "    connection = psycopg2.connect(database = db_name,\n",
    "    host = host,\n",
    "    user = user,\n",
    "    password = password     \n",
    "    )\n",
    "    return connection\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql://{user}:{password}@{host}/{db_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for getting Nasdaq 100 tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.5672.64 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_endpoints = [\"\", \"&r=21\", \"&r=41\", \"&r=61\", \"&r=81\"]\n",
    "list_of_tickers = []\n",
    "sleep_period = 0\n",
    "for i in list_of_endpoints:\n",
    "    file_to_parse = requests.get(f\"https://finviz.com/screener.ashx?v=111&f=exch_nasd,geo_usa,idx_ndx{i}\", headers=headers).text\n",
    "    soup = BeautifulSoup(file_to_parse, \"lxml\")\n",
    "    lines_tr_full = soup.find_all(\"tr\", valign = \"top\")\n",
    "    for lines_tr in lines_tr_full:\n",
    "        lines_td = lines_tr.find(\"td\", align = \"left\").a.text\n",
    "        list_of_tickers.append(lines_td)\n",
    "    sleep_period+=2\n",
    "    time.sleep(sleep_period) \n",
    "df = pd.DataFrame(list_of_tickers, columns=[\"ticker\"])\n",
    "df.to_sql(\"tickers\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all tickers from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] the connection was closed\n",
      "['AAPL', 'ABNB', 'ADBE', 'ADI', 'ADP', 'ADSK', 'AEP', 'ALGN', 'AMAT', 'AMD', 'AMGN', 'AMZN', 'ANSS', 'ATVI', 'AVGO', 'BIIB', 'BKNG', 'BKR', 'CDNS', 'CEG', 'CHTR', 'CMCSA', 'COST', 'CPRT', 'CRWD', 'CSCO', 'CSGP', 'CSX', 'CTAS', 'CTSH', 'DDOG', 'DLTR', 'DXCM', 'EA', 'EBAY', 'ENPH', 'EXC', 'FANG', 'FAST', 'FISV', 'FTNT', 'GFS', 'GILD', 'GOOG', 'GOOGL', 'HON', 'IDXX', 'ILMN', 'INTC', 'INTU', 'ISRG', 'KDP', 'KHC', 'KLAC', 'LCID', 'LRCX', 'MAR', 'MCHP', 'MDLZ', 'META', 'MNST', 'MRNA', 'MRVL', 'MSFT', 'MU', 'NFLX', 'NVDA', 'ODFL', 'ORLY', 'PANW', 'PAYX', 'PCAR', 'PEP', 'PYPL', 'QCOM', 'REGN', 'RIVN', 'ROST', 'SBUX', 'SGEN', 'SIRI', 'SNPS', 'TMUS', 'TSLA', 'TXN', 'VRSK', 'VRTX', 'WBA', 'WBD', 'WDAY', 'XEL', 'ZM', 'ZS']\n"
     ]
    }
   ],
   "source": [
    "connection = set_connection() \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"SELECT ticker FROM tickers\")\n",
    "        alltickers = cursor.fetchall()\n",
    "except Exception as exc:\n",
    "    print (f\"INFO: Exception occured while woring to database {exc}\")\n",
    "finally:\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        print(\"[INFO] the connection was closed\")\n",
    "alltickers2 = [i[0] for i in alltickers]\n",
    "print(alltickers2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for getting metrics for Nasdaq 100 tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_metrics = []\n",
    "tickers_for_list_of_metrics = []\n",
    "names_for_list_of_metrics = []\n",
    "for ticker in alltickers2:\n",
    "    file_to_parse = requests.get(f\"https://finviz.com/quote.ashx?t={ticker}&p=d\", headers=headers).text\n",
    "    soup = BeautifulSoup(file_to_parse, \"lxml\")\n",
    "    lines_tr_full = soup.find_all(\"td\", class_ = \"snapshot-td2\")\n",
    "    for i in lines_tr_full:\n",
    "        tickers_for_list_of_metrics.append(ticker)\n",
    "        list_of_metrics.append(i.find(\"b\").text)\n",
    "    lines_tr_full = soup.find_all(\"td\", class_ = \"snapshot-td2-cp\")\n",
    "    for i in lines_tr_full:\n",
    "        names_for_list_of_metrics.append(i.text)\n",
    "    time.sleep(3)\n",
    "cap_list = []\n",
    "tickers_for_cap_list = []\n",
    "for i in range(6, len(list_of_metrics), 72):\n",
    "    cap_list.append(list_of_metrics[i][:-1])\n",
    "for i in range(6, len(tickers_for_list_of_metrics),72):\n",
    "    tickers_for_cap_list.append(tickers_for_list_of_metrics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_list = []\n",
    "tickers_for_cap_list = []\n",
    "for i in range(6, len(list_of_metrics), 72):\n",
    "    cap_list.append(list_of_metrics[i][:-1])\n",
    "for i in range(6, len(tickers_for_list_of_metrics),72):\n",
    "    tickers_for_cap_list.append(tickers_for_list_of_metrics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "print(len(tickers_for_cap_list))\n",
    "print(len(cap_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'ticker':tickers_for_cap_list, 'market_cap':cap_list})\n",
    "df.to_sql(\"market_cap\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6696\n",
      "6696\n",
      "6696\n"
     ]
    }
   ],
   "source": [
    "print(len(tickers_for_list_of_metrics))\n",
    "print(len(list_of_metrics))\n",
    "print(len(names_for_list_of_metrics ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'ticker':tickers_for_list_of_metrics, 'metrics':list_of_metrics, 'name':names_for_list_of_metrics})\n",
    "df.to_sql(\"metrics_fin\", engine, if_exists=\"append\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
